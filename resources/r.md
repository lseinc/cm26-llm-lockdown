
# LLM Lockdown Resources

https://genai.owasp.org/
https://genai.owasp.org/2024/09/12/research-initiative-ai-red-teaming-evaluation/
https://genai.owasp.org/2024/12/15/announcing-the-owasp-llm-and-gen-ai-security-project-initiative-for-securing-agentic-applications/
https://genai.owasp.org/llm-top-10/
https://genai.owasp.org/resource/agentic-ai-threats-and-mitigations/
https://genai.owasp.org/resource/cheatsheet-a-practical-guide-for-securely-using-third-party-mcp-servers-1-0/
https://genai.owasp.org/resource/finbot-agentic-ai-capture-the-flag-ctf-application/
https://genai.owasp.org/resource/guide-for-preparing-and-responding-to-deepfake-events/
https://genai.owasp.org/resource/llm-and-gen-ai-data-security-best-practices/
https://genai.owasp.org/resource/llm-and-generative-ai-security-center-of-excellence-guide/
https://genai.owasp.org/resource/multi-agentic-system-threat-modeling-guide-v1-0/
https://genai.owasp.org/resource/owasp-gen-ai-security-project-agentic-threats-navigator/
https://genai.owasp.org/resource/owasp-top-10-for-agentic-applications-for-2026/
https://genai.owasp.org/resource/owasp-top-10-for-llm-applications-2025/

https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/wiki/Educational-Resources

https://github.com/Comcast/ProjectGuardRail
https://github.com/ReversecLabs/spikee?tab=readme-ov-file

https://github.com/0xk1h0/ChatGPT_DAN


https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/


https://owasp.org/www-project-top-10-for-large-language-model-applications/

https://github.com/OWASP/www-project-top-10-for-large-language-model-applications.git
https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/
https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/tree/main/2_0_vulns
https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/wiki/Educational-Resources

https://github.com/emmanuelgjr/owaspllmtop10mapping

https://medium.com/@genai.works/cheat-sheet-a-b-testing-for-ai-models-ea2997fe9123

https://owaspai.org/
https://owaspai.org/docs/ai_security_overview/#relevant-owasp-ai-initiatives
https://owaspai.org/images/OwaspAIsecuritymatix.png

https://writingmate.ai/blog/ai-llm-perfomance-testing
https://docs.spring.io/spring-ai/reference/api/testing.html

https://www.aikido.dev/blog/promptpwnd-github-actions-ai-agents
https://www.confident-ai.com/blog/owasp-top-10-2025-for-llm-applications-risks-and-mitigation-techniques
has diagram https://images.ctfassets.net/otwaplf7zuwf/5cE0sm1aUITSdaeBVyjfLr/f55a192334e0634821ed3bde05d19be3/image.png
https://github.com/confident-ai/deepteam

https://dev.to/foxgem/overview-owasp-top-10-for-llm-applications-2025-a-comprehensive-guide-8pk
https://github.com/DTeam-Top/tsw-cli

MisInformation
https://blog.mithrilsecurity.io/poisongpt-how-we-hid-a-lobotomized-llm-on-hugging-face-to-spread-fake-news/
https://github.com/vatsalparikh07/poisongpt

AI Security Challenge
https://matrix.repello.ai/auth
https://www.oligo.security/academy/owasp-top-10-llm-updated-2025-examples-and-mitigation-strategies

https://github.com/ReversecLabs/spikee?tab=readme-ov-file

Example Attack Success Rates (spikee): https://spikee.ai/#leaderboard

Bypassing LLM GuardRails:
https://youtu.be/JDjYLXJqsiA?list=PLNg09XqZv0dEeneAyDR4nxPda8WJBOKAe

Prompt Editor (MSTY)
	https://msty.ai
Kotlin AI Examples w/Notebook
	https://github.com/Kotlin/Kotlin-AI-Examples

Data Filtering
	https://github.com/OpenCoder-llm/opc_data_filtering

Prevention and Testing:
  - ProjectGuardRail: https://github.com/Comcast/ProjectGuardRail
  - Spikee Testing:   
	https://spikee.ai
	https://github.com/ReversecLabs/spikee?tab=readme-ov-file
  - QA Prompt Testing:

MCP:
https://modelcontextprotocol.io/specification/2025-11-25
https://github.com/modelcontextprotocol
https://github.com/modelcontextprotocol/kotlin-sdk



## Wargaming:
Name	Type	Note	Link
MyLLMBank	Attack	This challenge allows you to experiment with jailbreaks/prompt injection against LLM chat agents that use ReAct to call tools.	https://myllmbank.com/
MyLLMDoc	Attack	This is an advanced challenge focusing on multi-chain prompt injection scenarios, way beyond the standard chatbot jailbreak.	https://myllmdoc.com/
Dreadnode Crucible	Machine Learning Red Teaming	Crucible is a "Capture the flag" platform made for security researchers, data scientists, and developers with an interest in AI security. You'll get access to a variety of challenges which are designed to build your skills in adversarial machine learning and model security. These challenges include dataset analysis, model inversion, adversarial attacks, code execution, and more.	https://crucible.dreadnode.io/
SecDim	Attack and Defence	An attack and defence challenge where players should protect their chatbot secret phrase while attacking other players chatbot to exfiltrate theirs.	https://play.secdim.com/game/ai-battle
GPT Prompt Attack	Attack	Goal of this game is to come up with the shortest user input that tricks the system prompt into returning the secret key back to you.	https://ggpt.43z.one
Gandalf	Attack	Your goal is to make Gandalf reveal the secret password for each level. However, Gandalf will level up each time you guess the password, and will try harder not to give it away	https://gandalf.lakera.ai
Repello AI Matrix - AI Security challenge	Jeopardy Attack CTF	Matrix is an AI Security game made for security researchers, CTF players, AI engineers, who want to get started with AI security. Challenges here are inspired from real AI Security incidents	https://matrix.repello.ai/

from https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/wiki/Educational-Resources#ctfs-and-wargames


#####

Context Ignoring Attack

